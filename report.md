# Reporte de Resultados ‚Äì Laboratorio AutoML con DVC

**Autora:** Brenda Guiselle Chur Chinchilla  
**Curso:** Product Development  

---

## 1. Objetivo

Dise√±ar un pipeline automatizado inspirado en AutoML, utilizando **DVC (Data Version Control)** y **Git** para gestionar datasets, modelos y experimentos de forma reproducible.

---

## 2. Descripci√≥n general

Este laboratorio implementa un pipeline reproducible de aprendizaje autom√°tico controlado con DVC y Git, capaz de:

- Preprocesar datos autom√°ticamente seg√∫n su tipo.  
- Entrenar y comparar distintos modelos (Regresi√≥n Lineal y Random Forest).  
- Evaluar m√©tricas (R¬≤ y RMSE) y registrar resultados con versionado de datos y configuraciones.  
- Analizar c√≥mo los cambios en el dataset afectan el rendimiento del modelo.

---

## 3. Versiones del dataset y resultados

| Versi√≥n | Descripci√≥n                                                                                   | R¬≤      | RMSE     |
|:-------:|:----------------------------------------------------------------------------------------------|--------:|---------:|
| **V1** | Dataset original sin modificaciones. Se estableci√≥ el pipeline base (preprocess ‚Üí train ‚Üí evaluate). | 0.6468  | 0.68032  |
| **V2** | Limpieza, eliminaci√≥n de filas duplicadas y valores nulos.                                    | 0.6468  | 0.68032  |
| **V3** | Ampliaci√≥n, se agregaron nuevas observaciones (~20% m√°s registros).                           | 0.65647 | 0.67852  |
| **V4** | Transformaci√≥n: creaci√≥n de nuevas variables (*RoomsPerPerson*, *BedroomsPerRoom*) y eliminaci√≥n de las columnas originales. | 0.65092 | 0.68399  |
| **V5** | Tratamiento de outliers, eliminaci√≥n de valores extremos en *MedHouseVal*.                    | 0.64799 | 0.67767  |

> Las m√©tricas se registraron autom√°ticamente en `metrics.json` y fueron comparadas con los comandos:
> ```bash
> dvc metrics show
> dvc metrics diff v1_data v5_data
> ```

---

## 4. Modelo ganador y par√°metros finales

A partir de la versi√≥n final del dataset (V5), el modelo con mejor rendimiento fue **Random Forest**, determinado mediante el RMSE en el conjunto de entrenamiento.

**Modelo ganador:** Random Forest  
**M√©trica principal:** RMSE  
**M√©tricas en test (V5):**
- RMSE = 0.67767  
- R¬≤ = 0.64799  

**Hiperpar√°metros finales del modelo:**
- `n_estimators = 100`  
- `max_depth = 5`  
- `random_state = 42`

Los archivos generados en el pipeline fueron:
- `models/best_model.joblib` ‚Üí modelo entrenado y seleccionado autom√°ticamente.  
- `models/best_model_info.json` ‚Üí registro de resultados de todos los modelos.  
- `metrics.json` ‚Üí m√©tricas finales del modelo ganador.

---

## 5. Comparaci√≥n y an√°lisis de resultados

Los resultados muestran c√≥mo los cambios progresivos en el dataset afectaron el rendimiento del modelo:

- **V1 ‚Üí V2 (Limpieza de duplicados y nulos):**  
  No hubo cambios en las m√©tricas, lo que indica que el dataset original ya estaba limpio y sin valores redundantes.

- **V2 ‚Üí V3 (Ampliaci√≥n de datos):**  
  Se observ√≥ una mejora leve en el rendimiento (R¬≤ aument√≥ y RMSE disminuy√≥).  
  El incremento del tama√±o del dataset (~20%) permiti√≥ al modelo generalizar mejor.

- **V3 ‚Üí V4 (Nuevas variables derivadas):**  
  Las transformaciones no mejoraron el desempe√±o; el RMSE aument√≥ ligeramente.  
  Esto sugiere que las variables creadas no aportaron informaci√≥n predictiva adicional o eliminaron relaciones relevantes.

- **V4 ‚Üí V5 (Tratamiento de outliers):**  
  El rendimiento mejor√≥ nuevamente, con una reducci√≥n del RMSE y un R¬≤ estable.  
  La eliminaci√≥n de valores extremos ayud√≥ a estabilizar el modelo y reducir la influencia de observaciones at√≠picas.

- **V1 ‚Üí V5 (Comparaci√≥n global):**  
  El modelo final present√≥ una peque√±a mejora global respecto a la versi√≥n inicial, destacando el impacto positivo de la ampliaci√≥n del dataset y la correcci√≥n de outliers.

---

## 6. Conclusiones

1. El uso de **DVC** permiti√≥ controlar la evoluci√≥n del pipeline, versionar datos, m√©tricas y modelos de forma reproducible.  
2. Las comparaciones con `dvc metrics diff` evidenciaron c√≥mo la calidad y cantidad de datos influyen directamente en el rendimiento del modelo.  
3. Las transformaciones de variables deben validarse emp√≠ricamente, ya que no todas contribuyen a una mejora en el desempe√±o.  
4. El **Random Forest** se consolid√≥ como el mejor modelo para este conjunto de datos, combinando bajo error (RMSE) con buena capacidad de generalizaci√≥n.  
5. En conjunto, las mejoras aplicadas al dataset lograron estabilizar y optimizar el rendimiento del pipeline automatizado de aprendizaje autom√°tico.

---

üìÑ **Comandos clave del an√°lisis:**
```bash
dvc repro
dvc metrics show
dvc metrics diff v1_data v5_data


